# SAPP---IIND---005786
Repositorio del curso Sistemas Avanzados de Producci√≥n con Python (Departamento de Ingenier√≠a Industrial ECCI) 2025-II


---

## üìÖ Cronograma del curso

---

### **M√≥dulo 1**

| Semana                     | Tema a tratar                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Objetivo                                                                                                                                                             | Actividad   | Drive del curso                                  | Porcentaje Nota/Entrega                                               |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- | ------------------------------------------------ | --------------------------------------------------------------------- |
| **11 al 15 de agosto**     | - Configurar el entorno en Google Colab (montar Drive, guardar copia en GitHub).<br>- Conocer la estructura del notebook (celdas de c√≥digo y Markdown); ejecutar celdas y usar atajos b√°sicos.<br>- Escribir primeras l√≠neas de Python: variables, tipos (int/float/str/bool), operadores, listas y diccionarios.<br>- Importar y verificar librer√≠as: numpy, pandas, matplotlib, seaborn, statsmodels.<br>- Cargar un CSV simple y crear la primera visualizaci√≥n (histograma y gr√°fico de barras). | Dejar operativo el entorno y que el estudiante ejecute celdas, escriba c√≥digo b√°sico en un notebook y genere su primer gr√°fico, dejando evidencia en su repositorio. | Taller 1    | `NB-01_Colab_GitHub_Primeros_Pasos.ipynb`        | **5%** (Entrega Taller 1 viernes 22 de agosto a m√°s tardar 11:59 P.M) |
| **18 (F) al 22 de agosto** | - Cargar un dataset desde Drive o URL (CSV).<br>- Explorar: `.shape`, `.columns`, `.dtypes`, `.head`, `.describe`.<br>- Detectar valores faltantes y duplicados; calcular conteos y porcentajes.<br>- Resumir variables num√©ricas y categ√≥ricas; crear tablas de frecuencias.<br>- Visualizar: histogramas, boxplots, dispersi√≥n y barras agrupadas.<br>- Filtrar/seleccionar columnas y filas; crear una columna derivada con pandas.                                                               | Realizar un EDA b√°sico y documentar hallazgos con texto y gr√°ficos en el notebook.                                                                                   | Taller 1, 2 | `NB-02_EDA_Basico.ipynb`                         |                                                                       |
| **25 al 29 de agosto**     | - Diferenciar poblaci√≥n y muestra; tomar muestras simples con NumPy/pandas.<br>- Simular distribuci√≥n de medias muestrales y evidenciar el TCL.<br>- Implementar bootstrap para intervalos de confianza de la media/mediana.<br>- Calcular correlaci√≥n de Pearson e interpretar el signo y magnitud.<br>- Ajustar una regresi√≥n lineal simple e interpretar la pendiente y el intercepto.<br>- Mostrar la Paradoja de Simpson con un ejemplo y discutir su impacto.                                  | Comprender muestreo e incertidumbre y ajustar/interpetar un modelo lineal simple aplicado a datos de producci√≥n/servicios.                                           | Taller 2    | `NB-03_Muestreo_Bootstrap_RegresionSimple.ipynb` | **5%** (Entrega Taller 2 viernes 29 de agosto a m√°s tardar 11:59 P.M) |
| **1 al 6 de septiembre**   | Revisi√≥n de Notas y Parcial                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Evaluar competencias iniciales de EDA, muestreo y regresi√≥n simple usando notebooks.                                                                                 | Parcial 1   | `NB-EX1_Parcial_Introduccion_EDA.ipynb`          | **10%**                                                               |

---

### **M√≥dulo 2**

| Semana                               | Tema a tratar                                                                                                                                                                                                                                                                                                                                                                                                                    | Objetivo                                                                                                 | Actividad | Drive del curso                                 | Porcentaje Nota/Entrega                                                    |
| ------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | --------- | ----------------------------------------------- | -------------------------------------------------------------------------- |
| **8 al 12 de septiembre**            | - Diferenciar aprendizaje supervisado vs. no supervisado con ejemplos de ingenier√≠a industrial.<br>- Definir flujo de trabajo: divisi√≥n entrenamiento/prueba, m√©tricas y validaci√≥n.<br>- Preparar dataset (selecci√≥n de variables, escalado b√°sico).<br>- Entrenar un primer modelo de regresi√≥n con scikit-learn (train/test) y calcular R¬≤ y MSE.<br>- Graficar predicciones y residuos; registrar resultados en el notebook. | Entender el marco general de ML y entrenar el primer modelo con scikit-learn de forma reproducible.      | Taller 3  | `NB-04_Introduccion_ML_Regresion_sklearn.ipynb` | **10%** (Entrega Taller 3 viernes 19 de septiembre a m√°s tardar 11:59 P.M) |
| **15 al 19 de septiembre**           | - Ajustar regresi√≥n lineal m√∫ltiple con scikit-learn/statsmodels.<br>- Interpretar coeficientes (unidades, se√±ales) y revisar multicolinealidad b√°sica.<br>- Evaluar supuestos mediante an√°lisis de residuos y gr√°ficos diagn√≥sticos.<br>- Comparar modelos con y sin variables; reporte de m√©tricas en tabla.<br>- Aplicar validaci√≥n cruzada k-fold para estimar desempe√±o.                                                    | Construir y evaluar regresi√≥n m√∫ltiple, interpretando resultados con foco en procesos y mejora continua. | Taller 3  | `NB-05_Regresion_Multiple_Evaluacion.ipynb`     |                                                                            |
| **22 al 26 de septiembre**           | - Identificar sobreajuste y subajuste con m√©tricas y curvas de aprendizaje.<br>- Aplicar regularizaci√≥n Ridge y Lasso; comparar coeficientes y desempe√±o.<br>- Usar GridSearchCV para elegir hiperpar√°metros con validaci√≥n cruzada.<br>- Documentar conclusiones y selecci√≥n final del modelo.                                                                                                                                  | Mejorar la generalizaci√≥n usando regularizaci√≥n y validaci√≥n cruzada para seleccionar hiperpar√°metros.   | Taller 4  | `NB-06_Regularizacion_Ridge_Lasso_CV.ipynb`     | **10%** (Entrega Taller 4 viernes 29 de septiembre a m√°s tardar 11:59 P.M) |
| **29 de septiembre al 3 de octubre** | - Introducir √°rboles de decisi√≥n para clasificaci√≥n.<br>- Preparar datos (train/test), entrenar un √°rbol y evaluar con matriz de confusi√≥n y F1.<br>- Visualizar el √°rbol y obtener importancia de variables.<br>- Ajustar hiperpar√°metros (`max_depth`, `min_samples_leaf`) y comparar resultados.                                                                                                                              | Resolver un problema de clasificaci√≥n con √°rboles y evaluar su rendimiento con m√©tricas adecuadas.       | Taller 4  | `NB-07_Arboles_Clasificacion.ipynb`             |                                                                            |
| **6 al 11 de octubre**               | Revisi√≥n de Notas y Parcial                                                                                                                                                                                                                                                                                                                                                                                                      | Comprobar dominio de modelado (regresi√≥n/regularizaci√≥n/√°rboles) con un caso aplicado.                   | Parcial 2 | `NB-EX2_Parcial_Modelado_Validacion.ipynb`      | **10%**                                                                    |

---

### **M√≥dulo 3**

| Semana                        | Tema a tratar                                                                                                                                                                                                                                                                                                                                                                                              | Objetivo                                                                                                       | Actividad | Drive del curso                               | Porcentaje Nota/Entrega                                                  |
| ----------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- | --------- | --------------------------------------------- | ------------------------------------------------------------------------ |
| **13 (F) al 17 de octubre**   | - Formular el proyecto (pregunta de negocio, variable objetivo y m√©tricas).<br>- Cargar y perfilar datos de m√∫ltiples fuentes (CSV/Excel); corregir tipos y nombres.<br>- Detectar y tratar valores faltantes (mapeo de c√≥digos e imputaci√≥n simple).<br>- Estandarizar/normalizar variables num√©ricas con scikit-learn.<br>- Crear variables derivadas (ratios, indicadores) relevantes para el proyecto. | Dejar un dataset limpio y documentado, listo para modelado, con decisiones de preparaci√≥n justificadas.        | Taller 5  | `NB-08_Perfilamiento_Limpieza_Features.ipynb` | **15%** (Entrega Taller 5 viernes 24 de octubre a m√°s tardar 11:59 P.M)  |
| **20 al 24 de octubre**       | - Resolver duplicados con pandas y verificar consistencia.<br>- Codificar variables categ√≥ricas (`get_dummies` / `OneHotEncoder`).<br>- Integrar tablas con `pandas.merge/join` y validar cardinalidades.<br>- Incorporar columnas de texto al dataset (como variables auxiliares).                                                                                                                        | Consolidar e integrar datos de m√∫ltiples fuentes y dejar categ√≥ricas codificadas para modelado.                | Taller 5  | `NB-09_Integracion_OneHotEncoding.ipynb`      |                                                                          |
| **27 al 31 de octubre**       | - Preparar texto: limpieza b√°sica (min√∫sculas, tildes, signos) y tokenizaci√≥n.<br>- Representar documentos con bolsa de palabras (`CountVectorizer`).<br>- Aplicar selecci√≥n de atributos simple (`VarianceThreshold` / `SelectKBest`).<br>- Dejar pipeline reproducible de preprocesamiento de texto.                                                                                                     | Introducir el procesamiento de texto y construir un pipeline b√°sico para representar documentos como vectores. | Taller 6  | `NB-10_Texto_Basico_Pipeline.ipynb`           | **15%** (Entrega Taller 6 viernes 7 de noviembre a m√°s tardar 11:59 P.M) |
| **3 (F) al 7 de noviembre**   | - Remover stopwords y aplicar stemming/lematizaci√≥n (NLTK/spaCy en Colab).<br>- Representar texto con TF-IDF (`TfidfVectorizer`).<br>- (Opcional) Entrenar un clasificador de texto y evaluar (accuracy/F1).                                                                                                                                                                                               | Profundizar preprocesamiento de texto y usar TF-IDF como representaci√≥n num√©rica lista para modelado.          | Taller 6  | `NB-11_Texto_Avanzado_TFIDF.ipynb`            |                                                                          |
| **10 al 14 de noviembre**     | - Repaso general de m√≥dulos 1‚Äì3.<br>- Preparaci√≥n del caso integrador final en notebook.                                                                                                                                                                                                                                                                                                                   | Consolidar competencias para el caso final (datos ‚Üí modelo ‚Üí conclusiones accionables).                        |           | `NB-12_Repaso_General.ipynb`                  |                                                                          |
| **17 (F) al 24 de noviembre** | Revisi√≥n de Notas y Parcial Final                                                                                                                                                                                                                                                                                                                                                                          | Evaluaci√≥n final integradora con enfoque pr√°ctico y reporte reproducible.                                      | Parcial 3 | `NB-EX3_Parcial_Final_Caso_Integrador.ipynb`  | **20%**                                                                  |

---

